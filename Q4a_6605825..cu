/*
 ============================================================================
 Name        : Q4.cu
 Author      : Wish Suharitdamrong
 Version     :
 Copyright   : Your copyright notice
 Description : CUDA compute reciprocals
 ============================================================================
 */
#include <iostream>
#include <numeric>
#include <stdlib.h>
#include <cuda.h>
#include <math.h>

// Array Size
#define N 65535
// Size of share memory
#define SHARE_MEM 256



/*
 *
 *  Reduce Kernel : Parallel Reduction
 *
 * */
__global__ void reduceKernel(int * input_d,int * output_d){

	// Declare shared memory array size of block size
	__shared__ int shared_data[SHARE_MEM];

	// each thread loads one element from global to shared memory
	// Thread id inside a blocks
	unsigned int tid = threadIdx.x;
	// Thread id
	unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;

	// copy value from global memory to shared memory
	shared_data[tid] = input_d[i];



	// wait for other threads to finish
	__syncthreads();


	for (unsigned int s=1; s < blockDim.x; s *= 2) {
	int index = 2 * s * tid;
		if (index < blockDim.x) {
			shared_data[index] += shared_data[index + s];

		}
	// wait for other thread to finish
	__syncthreads();
	}

	// write result for this block to global memory , it will write back only one time in each block
	if (tid == 0){
		// write the value to global memory
		output_d[blockIdx.x] = shared_data[0];


	}

}


/*
 *
 *
 * */
void init(int * input_hdata){
	//  initialise value in an array
	for(int i =0 ;i<N;i++){
		input_hdata[i]=i;

	}
	// print out the value in an array
	printf("Initialise value in an array \n");



	printf("\n\n");

}

/**
 *
 *the reduction sums  of  reduce value generated by each individual blocks by using CPU
 *
 * **/
void FinalReduce(int * output_hdata, int GridSize){
		int sum = 0;

		for (int i=0;i<GridSize;i++){

			sum=sum+output_hdata[i];

		}
		printf("Final reduce value: %d", sum);
}

int main(void){


	int * input_hdata;
	int * output_hdata;

	// Allocate a dynamic memory for input and output in the Host (CPU)
	input_hdata = (int*)malloc(N*sizeof(int));
	output_hdata = (int*)malloc(N*sizeof(int));

	// intitialize a value to the input array of the host
	init(input_hdata);



	// Declare Number of thread
	int n = N;
	// Declare Number of thread in block
	int blockSize;

	// calculate a suitable block size for N array **To avoid bank conflict**
	if(n<=32){
		blockSize = 4;
	}else if((n>32) && (n<=1025)){
		blockSize = 32;
	}else{
		blockSize = 256;
	}




	// Declare Number of block
	unsigned int GridSize =(n+blockSize-1)/blockSize;
	printf("Size of an array %f \n",n);
	printf("BlockSize %d \n",blockSize);
	printf("GridSize %d \n",GridSize);

	// Create a variable for input and output data for Device(GPU)
	int * input_d;
	int * output_d;


	printf("\nAllocate and copy memory from host to Device\n");
	// Allocate and copy memory from host to Device
	cudaError_t err = cudaMalloc(&input_d,N*sizeof(int));
	printf("CUDA malloc i_d: %s\n",cudaGetErrorString(err));
	err = cudaMemcpy(input_d,input_hdata,N*sizeof(int),cudaMemcpyHostToDevice);
	printf("CUDA memcpy i_d: %s\n",cudaGetErrorString(err));
	err =cudaMalloc((void**)&output_d,N*sizeof(int));
	printf("CUDA malloc o_d: %s\n",cudaGetErrorString(err));
	err =cudaMemcpy(output_d,output_hdata,N*sizeof(int),cudaMemcpyHostToDevice);
	printf("CUDA memcpy o_d: %s\n",cudaGetErrorString(err));
	printf("\n");


	// Create a timer for kernel call
	float time=0;
	cudaEvent_t start, stop;
	cudaEventCreate (&start);
	cudaEventCreate (&stop);
	// place the start and stop events in the default stream, stream 0
	cudaEventRecord (start, 0);

	printf("Start the Kernel\n");
	// Call the kernel for the reduce function using Device(GPU)
	reduceKernel<<<GridSize,blockSize>>>(input_d,output_d);

	// Wait for Device(GPU) to finish executing
	cudaError_t cudaerr = cudaDeviceSynchronize();
	if (cudaerr != cudaSuccess){
		 printf("kernel launch failed with error \"%s\".\n",cudaGetErrorString(cudaerr));
	}
	// Perform the Kernel invocations here
	cudaEventRecord (stop, 0);
	cudaEventSynchronize (stop);
	cudaEventElapsedTime (&time, start, stop);
	cudaEventDestroy (start);
	cudaEventDestroy (stop);

	// print the time taken during kernel called
	printf("\n");
	printf("Elapsed time was: %f milliseconds\n", time);
	printf("\n");


	// Allocate and copy the memory back from Device to Host
	printf("Allocate and copy the memory back from Device to Host\n");
	err =cudaMemcpy(output_hdata,output_d,N*sizeof(int),cudaMemcpyDeviceToHost);
	printf("CUDA memcpy o_data: %s\n",cudaGetErrorString(err));
	err =cudaMemcpy(input_hdata,input_d,N*sizeof(int),cudaMemcpyDeviceToHost);
	printf("CUDA memcpy i_data: %s\n",cudaGetErrorString(err));

	// Free the Device memory
	err =cudaFree(output_d);
	printf("CUDA free o_data: %s\n",cudaGetErrorString(err));
	err =cudaFree(input_d);
	printf("CUDA free i_data: %s\n",cudaGetErrorString(err));

	printf("\n");
	printf("Final reduce with Host(CPU)\n");
	// Call the reduce function using Host(CPU)
	FinalReduce(output_hdata, GridSize);

	// Free the Host memory;
	free(input_hdata);
	free(output_hdata);



	return 0;
}
